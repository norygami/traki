---
comments: false
date: 2025-03-16
categories:
  - ANARCHY
---

# ExpectAtion

## Hey Friends! ðŸ‘‹

Welcome to 2025! Our first announcement of this year tackles two topics in particular.

First, a **SITREP** on AUTONOMY+. Technical aspects are the main ingredient of this post, since we already handled the narrative dimension [here](https://store.steampowered.com/news/app/1811440/view/507321174540159233). Secondly, I want to introduce and discuss a **paradigm** with massive implications for our project.

It's a technology with a good amount **controversy** â€“ so I'm incredibly eager to hear what you think. First, though: Let's start with something unproblematic!

## Status

<div class="md-embed md-embed--16-9">
<iframe allowfullscreen="" frameborder="0" src="https://www.youtube.com/embed/cxdU0xPErHE"></iframe>
</div>

AUTONOMY has around 120 maps, 18 characters and 9000 lines of dialogue. AUTONOMY+ will have to have as much â€“ if not more. I knew what was coming, but I didn't have a clear-cut **strategy**. Just a broad guideline: Whatever I'm able to produce in the daily aftermath of writing a 250-page book on *verbalized attribution of causality in German environmental discourse* is fine by me. 

Considering the state of 2025 (as of Season 3, Episode 13), I think we're hungry for good news! A large part of prologue's **maps** are in. I just finished Nestville, including the tiles, spawns and transfers. All the maps before that (DMZ and indoor places) are also done.

The next step will be to set up quests, event-specific logic and â€“ most importantly: the **dialogue**. It's hard to say how many lines belong to the prologue specifically, but I got a script to extract and post-process RPGMaker data. If we can import the lines (including speaker and conversation ID), we'd save ourselves tens, if not hundreds of hours.!

I'm getting hot and bothered by the sheer scale of it. Partially due to the process â€“ but also because I'm looking forward to the result. Once we reach parity with AUTONOMY, we can **optimize** 1923 from a 7/10 sequence-of-events towards a narrative masterpiece.
<!-- more -->

## Responsibility
![](/assets/blog/images/steam/2025/2ddc1a87e003b786b971e405a52b632ce6e0a380.png)
My new year's resolution still holds: focus on what [strike]I[/strike] we have. **Information warfare** is the ice in TRACHI's iceberg. For better or worse, it's also the defining feature of the early 20th-century.

Who believes what? And why should I believe them? If they want me to believe something, should I believe them more or less? These are the type of questions that should run through a **postmodern** human mind. If not, that's okay! There's plenty of time and places to learn.

One such place is TRACHI's DIscord (ðŸ‘‹). I've recently tried to involve both myself and its people. We conducted two surveys â€“ one about general **expectations** and one regarding a specific issue. Thankfully, I received detailed answers about what they expect from the game, the server and me. Above everything else, there's a high demand to peek behind the curtain.

Incidentally, that's exactly where we're going next!

## Perspective
![](/assets/blog/images/steam/2025/ab5d470ca5f9417859ce0541be5ca14e069b459b.png)
Barring a short stint in 2022 (InvAsion/AUTHORITY), our point-of-view is tied to a **top-down** angle. It's rather unfortunate, given that we have the means for so much more! In fact: Unity's camera is made with 3D in mind. 

Quite ironic, isn't it? Most of the (successful) products *Made-With-Unity* are 2D mobile games. Maybe that's why Unity's developers have vastly improved the **camera** with Unity 6. Although I wouldn't have upgraded the entire engine just for that, it's absolutely nice to have!

You might've seen tiles **jittering** â€“ or even tear a bit sometimes. It's a well-known problem. We have to force Vsync, avoid seamless zooms and conduct any camera transition with great care. However: The camera movement feels vastly more stable â€“ and I'm hoping to enable buttons for zooming in and out.

Beyond the camera's stability, there is another difficulty. As mentioned, the camera is locked in a 75Â° angle towards the ground. Compared to 'true' top-down games (see GTA 1 and 2), we need to project depth into a **2D space**. Some part of that is handled by the sprites. Our job is to manage the arrangement â€“ aka which sprite is rendered 'on-top' of other sprites.

## Worlds apart
![](/assets/blog/images/steam/2025/8c4312dfb47532ca51a91edfcf0098d3fb458745.png)
Both the old ([FSM](https://refmap-l.blog.jp/archives/cat_202341.html)) and new ([Szadi](https://szadiart.itch.io/)) tiles can partially cover characters. There's an inverse relationship between collision and **sprite-stacking**: The more you allow things to be behind other things (less collision), the more you'll have to worry about getting the layers wrong.

Take for example the larger trees in ParAdise. Even regular-sized characters can be completely hidden. Thus we implemented a second collider to **fade** the sprite by decreasing the Alpha (less opacity, more transparency). Admittedly, it's not exactly pretty. But it's one of those issues where I prioritize visibility over aesthetics.

That is: ***aesthetics*** in its modern sense. Originally, the term simply referred to *perception*. At some point in time, humans smuggled a positive evaluation (*pretty*) in. Semantic changes like that are one of my guilty-pleasures â€“ which is why I have a passionate love/hate relationship with the term *art*.

I remember the discussion: *Are video-games art?* It's one of those time-wasters like: *Do we call human decision trees 'free will'?* We can **translate** both questions into plain English: Is that object more important than another? Once we answer that, we'll just have to ask it again until we compared each object with all the other ones.

We'd transform an object into a vector with as many **dimensions** as there are combinations. If we then reduce the dimensions and apply a clustering algorithm with two preset clusters, we arrive at a dichotomy. Life, Death. Good, bad. Good (!), evil. Pretty, ugly. Humans, animals. Intelligent, dumb. Natural, cultural. Organic-

## Artificial
![](/assets/blog/images/steam/2025/1e21f825e51fa3be75807f0512c9dd35944d92dc.png)
If someone draws a bunch of pictures and I assemble them â€“ who made the final image? What if I took that image and ran it through a **[model](https://civitai.com/models/288584/autismmix-sdxl)** until I decide on a result? Maybe I'd even hand-draw individual masks to get the details right.

You see, whether something is art or not is irrelevant to me. I look at the world as a system defined by causality. One thing happens **because** other things happened before. No output if I didn't initiate it. No output without the Stella portraits. No output without a model. No model without a dataset.

Let's hear another example. Last year, I wrote a **dataset** for TRACHI's discord model. We also extended it with ingame dialogue. Someone could extract the dialogue and reenact TRACHI's story word by word. Would that be possible if I didn't upload the dataset? What if I never published the game? Unlikely, sure! Not impossible, though.

The good news is: It wouldn't be a problem. Unless the other guy came first and tried to push me out. I for one am not scared of **competition**. Whatever I do today, I'll do better tomorrow. If there's another entity on earth that could write what I write â€“ please be so kind and bring them to me.

So far my thoughts. Now I'd love to hear [**yours**](https://docs.google.com/forms/d/e/1FAIpQLSclZiXcN58BxvsNzOZSf2_09LYMO8hCnEny-c0q-4ZmN4ixGA/viewform)! Ideally, before I take off the safety and wrap the whole AI-debate into what I believe to be the underlying problem.

## Origo
![](/assets/blog/images/steam/2025/83c0bf1e084e4642b93ee66e17e6d218f04c7ce2.png)
I'm used to dealing with **3rd Party material**. From Unity, ORK, DS, Steam, FSM, Szadi, Holder, Visustella and several hundred pieces of BGM and SFX. I ranted in depth about PROs, half-baked EULAs and the world's obsession to put numbers in chains.

Yes, I know! I'm crying about things I can't have. But there is a deeper, much more justified rage. Once upon a time, we called the internet a **market of ideas**. Nowadays, it's a market for things. Blogs turned into monolithic microblogs filled with grifters of all kinds. Websites became click-sucking cookie spreaders that bombard you with ads and DSVGO-forms. 

The only thing missing is the sound of an eager chatbot poking you when your eye glances over the thirteenth SEO-oozing mention of AI. I know â€“ It's **everywhere**. The rate of slop contra content is rising at a rapid rate. Ten years after a short-lived outrage about the misuse of personal information, the data finally talks back. 

In 2025, we can create content through **regression**. Decades of engagement-driven algorithms encouraged quantity over quality. To make it, you have to say it â€“ over and over again. Worst of all, the system works like a bank: The more money (reach) you have, the more interest (engagement) you get.

Take it from me, because it's exactly what I'm doing right now! In fact: Fighting the fight for attention was one of the reasons for me to **prototype** image generation. Whether you're reading this post out of loyalty â€“ because or despite the cover â€“ I'll probably never know. Although I'm pretty confident there's a question on your mind.

*Will TRACHI go AI?*

## Pragmatics
![](/assets/blog/images/steam/2025/df84613c97dd4ea076cab904c3a733ae6f8b711d.png)
Let's run the numbers. We extrapolate our prototype to roundabout a **thousand portraits**. Obviously I wouldn't need 20 hours per portrait. On the other hand, neural networks are fuzzy by design. And I happen to be more of a rule-based algorithm guy. 

To be blunt: The effort involved demands a really good **reason**. The 2025 versions would need to be a significant upgrade. That is â€“ if you forego the controversy around intellectual property. There's voices that said they would stop supporting the game. The SDXL front would have to bring numbers and make themselves heard.

That being said, let's talk about overall options. Someone suggested **commissioning** artists. Last year, I spent around a hundred hours and a thousand USD on that. Could we commission a thousand portraits and receive the results in an affordable, timely and reliable way?

If you know the one, get him to contact me. It would not only be much appreciated, but also **morally** sound. Said artist would support a small, free indie game, after all! Until that someone special knocks on my door, we'll have to make due with what we have.

Which would in fact be my personal **favourite**: We leave things as they are. I'll keep fuming about [Visustella's Character Generator](https://visustella.itch.io/stella-character-generator) never getting its long promised update â€“ and put my efforts into something else. Not that TRACHI wouldn't profit from a visual upgrade! However, the games' core strength lies somewhere else.

You see, there's a much better way to incorporate my love for **Transformers**. One that's nowhere near as morally ambiguous and much closer to my expertise. Something that strikes directly into the name, message and point of TRACHI.

## Vox

<div class="md-embed md-embed--16-9">
<iframe allowfullscreen="" frameborder="0" src="https://www.youtube.com/embed/U4h7AbU4O3A"></iframe>
</div>

During the first round of playtesting in 2021, someone asked me whether I considered **voice-overs** a possibility. Of course! It's dialogue, after all. The text is just an abstraction of someone saying something out loud. Which begs the question: Why hasn't it happened yet?

Two reasons: Time and money. Hiring **professional VAs** is expensive. The more expensive, the less micromanagement I have to do. If I'd ask my friends (of which a lot have expressed interest), I'd expect double-digit hours with each of them just to rope them in. If one decides it's not for them at any point in the next ten years, it's back to start for that specific role.

You see, it's the same problem everywhere. My dreams are as large as the number of (current) characters. Be it portraits or VA, solutions need to be **scalable** and **sustainable**. More importantly, there is a moral issue here as well: If TRACHI's people are artificial, would it be right to push organic voices up their throats?

They deserve better. A voice not directly generated by **vocal chord**s, but the result of artificial weights and biases. Thanks to the best sides of humanity, we even got the data in this case!

## Populi
![](/assets/blog/images/steam/2025/85b0295b8883503c9f06527a4613d3afc7af952c.png)
To generate voices for a lot of **people**, we need â€“ you guessed it â€“ the voices of a lot of people. [Mozilla Common Voice](https://commonvoice.mozilla.org/) dataset is one of sources I'm already experimenting with. Just like the [LibriSpeech Corpus](https://www.openslr.org/12), people donate their voice to humanity.

I could write a dozen paragraphs about how this is exactly what the internet should be. For the sake of the reader, I'll save it for another day. The key point is: I'll continue prototyping **Text-To-Speech**. Not just for days, or weeks, but as part of my professional goal to comprehend the future of language.

And if it should conspire that all available **models** are derived from questionable data â€“ I'll train my own. I got 300GB of audio, much of the linguistic / CS expertise and some recently formed friendships with colleagues from the field of acoustics to help me out.

I try to manage my excitement, but it's outright *magical* to think about. Let's put our hands together and pray that the next **announcement** includes at least part of the prologue and â€“ maybe â€“ a bunch of artificial people with an artificial voice.

Thank you, Humanity! And thank YOU â€“ for listening! ðŸ˜Š

**much love**  
nory
